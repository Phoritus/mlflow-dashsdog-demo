{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a65821",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8923caa-79db-4385-bd73-12aa4beda32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2607e",
   "metadata": {},
   "source": [
    "### Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ee2a7f-9eb8-44a5-b9e9-1a6b7ad02349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ Random seed set to 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9283bf",
   "metadata": {},
   "source": [
    "### Create Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24cc25e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING SYNTHETIC IMBALANCED CLASSIFICATION DATASET\n",
      "============================================================\n",
      "âœ“ Synthetic dataset created\n",
      "Features shape: (20000, 5)\n",
      "Target shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CREATING SYNTHETIC IMBALANCED CLASSIFICATION DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create imbalanced dataset using sklearn's make_classification\n",
    "X, y = make_classification(\n",
    "    n_samples=20000,           # Total number of samples\n",
    "    n_features=5,              # Number of features\n",
    "    n_informative=4,           # Number of informative features\n",
    "    n_redundant=1,             # Number of redundant features\n",
    "    n_classes=2,               # Binary classification\n",
    "    n_clusters_per_class=2,    # Number of clusters per class\n",
    "    weights=[0.85, 0.15],      # Class distribution (85% class 0, 15% class 1)\n",
    "    flip_y=0.01,               # Fraction of samples with flipped labels (noise)\n",
    "    class_sep=0.8,             # Factor multiplying the hypercube size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"âœ“ Synthetic dataset created\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e832e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ DataFrame created\n",
      "Dataset shape: (20000, 6)\n",
      "Columns: ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with meaningful column names\n",
    "feature_names = ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5']\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"âœ“ DataFrame created\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a00f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS DISTRIBUTION ANALYSIS\n",
      "----------------------------------------\n",
      "Class counts:\n",
      "  Class 0: 16,921 (84.6%)\n",
      "  Class 1: 3,079 (15.4%)\n",
      "\n",
      "Class imbalance ratio: 5.50:1\n",
      "Minority class percentage: 15.4%\n"
     ]
    }
   ],
   "source": [
    "# Analyze class distribution\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "class_counts = df['target'].value_counts().sort_index()\n",
    "class_percentages = df['target'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"Class counts:\")\n",
    "for class_label, count in class_counts.items():\n",
    "    percentage = class_percentages[class_label]\n",
    "    print(f\"  Class {class_label}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"Minority class percentage: {class_percentages[1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70f07f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SYNTHETIC DATASET CREATION COMPLETED!\n",
      "============================================================\n",
      "ðŸ“Š Dataset Details:\n",
      "   â€¢ Total samples: 20,000\n",
      "   â€¢ Features: 5\n",
      "   â€¢ Classes: 2 (Binary classification)\n",
      "   â€¢ Class 0: 16,921 samples (84.6%)\n",
      "   â€¢ Class 1: 3,079 samples (15.4%)\n",
      "   â€¢ Imbalance ratio: 5.50:1\n",
      "\n",
      "ðŸŽ¯ Dataset is ready for classification experiments!\n",
      "   â€¢ Perfect for testing class imbalance handling techniques\n",
      "   â€¢ Suitable for ML model comparison\n",
      "   â€¢ Can be used with sampling strategies (SMOTE, undersampling, etc.)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SYNTHETIC DATASET CREATION COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"ðŸ“Š Dataset Details:\")\n",
    "print(f\"   â€¢ Total samples: {len(df):,}\")\n",
    "print(f\"   â€¢ Features: {len(feature_names)}\")\n",
    "print(f\"   â€¢ Classes: 2 (Binary classification)\")\n",
    "print(f\"   â€¢ Class 0: {class_counts[0]:,} samples ({class_percentages[0]:.1f}%)\")\n",
    "print(f\"   â€¢ Class 1: {class_counts[1]:,} samples ({class_percentages[1]:.1f}%)\")\n",
    "print(f\"   â€¢ Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Dataset is ready for classification experiments!\")\n",
    "print(f\"   â€¢ Perfect for testing class imbalance handling techniques\")\n",
    "print(f\"   â€¢ Suitable for ML model comparison\")\n",
    "print(f\"   â€¢ Can be used with sampling strategies (SMOTE, undersampling, etc.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81f53285-fe61-451a-9dfd-ed1cc6805210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from imblearn.combine import SMOTETomek\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a47d609-fad3-447f-be51-2bc533403ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (20000, 5)\n",
      "Target shape: (20000,)\n",
      "Feature columns: ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5']\n",
      "\n",
      "Original class distribution: Counter({0: 16921, 1: 3079})\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n",
    "\n",
    "# Check original class distribution\n",
    "print(f\"\\nOriginal class distribution: {Counter(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11423a3a-e04a-45c4-9042-52a71749af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data split completed\n",
      "Training set shape: (16000, 5)\n",
      "Test set shape: (4000, 5)\n",
      "Training set class distribution: Counter({0: 13537, 1: 2463})\n",
      "Test set class distribution: Counter({0: 3384, 1: 616})\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Data split completed\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training set class distribution: {Counter(y_train)}\")\n",
    "print(f\"Test set class distribution: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc842c00-1407-4d55-89e1-d8392317fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SMOTE-Tomek applied successfully\n",
      "Original training set: Counter({0: 13537, 1: 2463})\n",
      "Balanced training set: Counter({0: 13397, 1: 13397})\n",
      "Balanced training set shape: (26794, 5)\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE-Tomek for class balancing\n",
    "smotek = SMOTETomek(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smotek.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"âœ“ SMOTE-Tomek applied successfully\")\n",
    "print(f\"Original training set: {Counter(y_train)}\")\n",
    "print(f\"Balanced training set: {Counter(y_train_balanced)}\")\n",
    "print(f\"Balanced training set shape: {X_train_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5aedb2a6-6b77-4f31-b496-28ccb6c39375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model configurations defined\n",
      "  - Logistic Regression\n",
      "  - Random Forest\n",
      "  - XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Define models for training\n",
    "models_config = {\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'name': 'Logistic Regression'\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "        'name': 'Random Forest'\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'model': xgb.XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False),\n",
    "        'name': 'XGBoost'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ“ Model configurations defined\")\n",
    "for key, config in models_config.items():\n",
    "    print(f\"  - {config['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f0be292-ddc7-4616-8552-a118ae7f5e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING MODELS WITHOUT CLASS IMBALANCE HANDLING\n",
      "============================================================\n",
      "\n",
      "Training Logistic Regression...\n",
      "âœ“ Logistic Regression trained successfully\n",
      "  Accuracy: 0.8748\n",
      "  AUC Score: 0.6716\n",
      "\n",
      "Training Random Forest...\n",
      "âœ“ Random Forest trained successfully\n",
      "  Accuracy: 0.9403\n",
      "  AUC Score: 0.9405\n",
      "\n",
      "Training XGBoost...\n",
      "âœ“ XGBoost trained successfully\n",
      "  Accuracy: 0.9370\n",
      "  AUC Score: 0.9437\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING MODELS WITHOUT CLASS IMBALANCE HANDLING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dictionary to store models and results\n",
    "models_no_balance = {}\n",
    "results_no_balance = {}\n",
    "\n",
    "for model_key, config in models_config.items():\n",
    "    print(f\"\\nTraining {config['name']}...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    model = config['model']\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store model and results\n",
    "    models_no_balance[model_key] = model\n",
    "    results_no_balance[model_key] = {\n",
    "        'accuracy': accuracy,\n",
    "        'auc_score': auc_score,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ {config['name']} trained successfully\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "238c9af9-17d3-4bb5-8459-632be1c3c2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING MODELS WITH SMOTE-TOMEK CLASS BALANCING\n",
      "============================================================\n",
      "\n",
      "Training Logistic Regression with SMOTE-Tomek...\n",
      "âœ“ Logistic Regression trained with SMOTE-Tomek successfully\n",
      "  Accuracy: 0.6795\n",
      "  AUC Score: 0.6806\n",
      "\n",
      "Training Random Forest with SMOTE-Tomek...\n",
      "âœ“ Random Forest trained with SMOTE-Tomek successfully\n",
      "  Accuracy: 0.9263\n",
      "  AUC Score: 0.9404\n",
      "\n",
      "Training XGBoost with SMOTE-Tomek...\n",
      "âœ“ XGBoost trained with SMOTE-Tomek successfully\n",
      "  Accuracy: 0.9183\n",
      "  AUC Score: 0.9434\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING MODELS WITH SMOTE-TOMEK CLASS BALANCING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dictionary to store balanced models and results\n",
    "models_balanced = {}\n",
    "results_balanced = {}\n",
    "\n",
    "for model_key, config in models_config.items():\n",
    "    print(f\"\\nTraining {config['name']} with SMOTE-Tomek...\")\n",
    "    \n",
    "    # Create fresh model instance (to avoid any sklearn issues)\n",
    "    if model_key == 'logistic_regression':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif model_key == 'random_forest':\n",
    "        model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    elif model_key == 'xgboost':\n",
    "        model = xgb.XGBClassifier(random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "    \n",
    "    # Train on balanced data\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Make predictions on same test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store model and results\n",
    "    models_balanced[model_key] = model\n",
    "    results_balanced[model_key] = {\n",
    "        'accuracy': accuracy,\n",
    "        'auc_score': auc_score,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ {config['name']} trained with SMOTE-Tomek successfully\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324f0a2-c048-45ae-b169-dfbbb681ae08",
   "metadata": {},
   "source": [
    "### Import MLflow Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76ffcb31-3207-4357-af77-a32da614e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import mlflow.tracking\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2574b82c-f879-4504-abc5-1a1725f58318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 11:12:42 INFO mlflow.tracking.fluent: Experiment with name 'Synthetic_Imbalanced_Dataset' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ MLflow experiment 'Synthetic_Imbalanced_Dataset' setup successful\n",
      "âœ“ Tracking URI: http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "# Set up MLflow experiment\n",
    "experiment_name = \"Synthetic_Imbalanced_Dataset\"\n",
    "\n",
    "try:\n",
    "    # Set MLflow tracking URI (adjust if needed)\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    \n",
    "    # Set or create experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    print(f\"âœ“ MLflow experiment '{experiment_name}' setup successful\")\n",
    "    print(f\"âœ“ Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš  MLflow setup warning: {e}\")\n",
    "    print(\"Continuing with default MLflow setup...\")\n",
    "    mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000d2e47-c570-4f7c-9702-9461d2ffe658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 11:12:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOGGING MODELS WITHOUT CLASS BALANCING TO MLFLOW\n",
      "============================================================\n",
      "\n",
      "Logging Logistic Regression (No Balancing)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f908fb924f2b452d9628ff536b9b2897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Logistic Regression (No Balancing) logged successfully\n",
      "ðŸƒ View run Logistic Regression_No_Balancing at: http://127.0.0.1:5000/#/experiments/154537210038587388/runs/4c83d3772bf64a7a8a94f52fe0fc60d2\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/154537210038587388\n",
      "\n",
      "Logging Random Forest (No Balancing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 11:12:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc78f2a8a0374bd0b126942c2612ecd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 11:12:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Random Forest (No Balancing) logged successfully\n",
      "ðŸƒ View run Random Forest_No_Balancing at: http://127.0.0.1:5000/#/experiments/154537210038587388/runs/74818e8528464611af64ec19c3249148\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/154537210038587388\n",
      "\n",
      "Logging XGBoost (No Balancing)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ae5b3ac14247a0953ace55355fdef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ XGBoost (No Balancing) logged successfully\n",
      "ðŸƒ View run XGBoost_No_Balancing at: http://127.0.0.1:5000/#/experiments/154537210038587388/runs/81d58f88f19d47bfb85177477442747a\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/154537210038587388\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOGGING MODELS WITHOUT CLASS BALANCING TO MLFLOW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_key, config in models_config.items():\n",
    "    model_name = config['name']\n",
    "    model = models_no_balance[model_key]\n",
    "    results = results_no_balance[model_key]\n",
    "    \n",
    "    print(f\"\\nLogging {model_name} (No Balancing)...\")\n",
    "    \n",
    "    # Create run name\n",
    "    run_name = f\"{model_name}_No_Balancing\"\n",
    "    \n",
    "    try:\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            \n",
    "            # Log parameters\n",
    "            if model_key == 'logistic_regression':\n",
    "                mlflow.log_params({\n",
    "                    'model_type': 'Logistic Regression',\n",
    "                    'C': model.C,\n",
    "                    'penalty': model.penalty,\n",
    "                    'solver': model.solver,\n",
    "                    'max_iter': model.max_iter,\n",
    "                    'random_state': model.random_state,\n",
    "                    'class_balancing': 'None'\n",
    "                })\n",
    "                \n",
    "            elif model_key == 'random_forest':\n",
    "                mlflow.log_params({\n",
    "                    'model_type': 'Random Forest',\n",
    "                    'n_estimators': model.n_estimators,\n",
    "                    'max_depth': model.max_depth,\n",
    "                    'min_samples_split': model.min_samples_split,\n",
    "                    'min_samples_leaf': model.min_samples_leaf,\n",
    "                    'random_state': model.random_state,\n",
    "                    'class_balancing': 'None'\n",
    "                })\n",
    "                \n",
    "            elif model_key == 'xgboost':\n",
    "                mlflow.log_params({\n",
    "                    'model_type': 'XGBoost',\n",
    "                    'n_estimators': model.n_estimators,\n",
    "                    'max_depth': model.max_depth,\n",
    "                    'learning_rate': model.learning_rate,\n",
    "                    'subsample': model.subsample,\n",
    "                    'colsample_bytree': model.colsample_bytree,\n",
    "                    'random_state': model.random_state,\n",
    "                    'class_balancing': 'None'\n",
    "                })\n",
    "            \n",
    "            # Log training data info\n",
    "            mlflow.log_params({\n",
    "                'train_size': len(X_train),\n",
    "                'test_size': len(X_test),\n",
    "                'n_features': X_train.shape[1],\n",
    "                'class_0_train': sum(y_train == 0),\n",
    "                'class_1_train': sum(y_train == 1),\n",
    "                'original_imbalance_ratio': sum(y_train == 0) / sum(y_train == 1)\n",
    "            })\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics({\n",
    "                'accuracy': results['accuracy'],\n",
    "                'auc_score': results['auc_score']\n",
    "            })\n",
    "            \n",
    "            # Calculate and log additional metrics\n",
    "            y_pred = results['predictions']\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            \n",
    "            # Calculate precision, recall, f1 for each class\n",
    "            from sklearn.metrics import precision_recall_fscore_support\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "            \n",
    "            mlflow.log_metrics({\n",
    "                'precision_class_0': precision[0],\n",
    "                'recall_class_0': recall[0],\n",
    "                'f1_class_0': f1[0],\n",
    "                'precision_class_1': precision[1],\n",
    "                'recall_class_1': recall[1],\n",
    "                'f1_class_1': f1[1],\n",
    "                'true_negatives': int(tn),\n",
    "                'false_positives': int(fp),\n",
    "                'false_negatives': int(fn),\n",
    "                'true_positives': int(tp),\n",
    "                'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "                'sensitivity': tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            })\n",
    "            \n",
    "            # Log model\n",
    "            if model_key == 'xgboost':\n",
    "                mlflow.xgboost.log_model(model, \"model\", input_example=X_test.iloc[:5])\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(model, \"model\", input_example=X_test.iloc[:5])\n",
    "            \n",
    "            print(f\"âœ“ {model_name} (No Balancing) logged successfully\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error logging {model_name} (No Balancing): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "680661eb-ef1a-4268-bd72-bea714bf3863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOGGING MODELS WITH SMOTE-TOMEK BALANCING TO MLFLOW\n",
      "============================================================\n",
      "\n",
      "Logging Logistic Regression (With SMOTE-Tomek)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 11:12:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec0872f95b6483893609d9b60da535b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 11:13:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Logistic Regression (With SMOTE-Tomek) logged successfully\n",
      "ðŸƒ View run Logistic Regression_SMOTE_Tomek at: http://127.0.0.1:5000/#/experiments/154537210038587388/runs/7ac48869ec4a45de8c47bc4ee972cbbc\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/154537210038587388\n",
      "\n",
      "Logging Random Forest (With SMOTE-Tomek)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df76d715e27a4e3bb480d759fe7c3980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/14 11:13:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Random Forest (With SMOTE-Tomek) logged successfully\n",
      "ðŸƒ View run Random Forest_SMOTE_Tomek at: http://127.0.0.1:5000/#/experiments/154537210038587388/runs/4478c5bdd08a449ea5e6ff2a0041d00a\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/154537210038587388\n",
      "\n",
      "Logging XGBoost (With SMOTE-Tomek)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6985af2a63ae477189abf94d71199f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ XGBoost (With SMOTE-Tomek) logged successfully\n",
      "ðŸƒ View run XGBoost_SMOTE_Tomek at: http://127.0.0.1:5000/#/experiments/154537210038587388/runs/f9afcb24b377482e870deffbee8c33a5\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/154537210038587388\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOGGING MODELS WITH SMOTE-TOMEK BALANCING TO MLFLOW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for model_key, config in models_config.items():\n",
    "    model_name = config['name']\n",
    "    model = models_balanced[model_key]\n",
    "    results = results_balanced[model_key]\n",
    "    \n",
    "    print(f\"\\nLogging {model_name} (With SMOTE-Tomek)...\")\n",
    "    \n",
    "    # Create run name\n",
    "    run_name = f\"{model_name}_SMOTE_Tomek\"\n",
    "    \n",
    "    try:\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            \n",
    "            # Log parameters\n",
    "            if model_key == 'logistic_regression':\n",
    "                mlflow.log_params({\n",
    "                    'model_type': 'Logistic Regression',\n",
    "                    'C': model.C,\n",
    "                    'penalty': model.penalty,\n",
    "                    'solver': model.solver,\n",
    "                    'max_iter': model.max_iter,\n",
    "                    'random_state': model.random_state,\n",
    "                    'class_balancing': 'SMOTE-Tomek'\n",
    "                })\n",
    "                \n",
    "            elif model_key == 'random_forest':\n",
    "                mlflow.log_params({\n",
    "                    'model_type': 'Random Forest',\n",
    "                    'n_estimators': model.n_estimators,\n",
    "                    'max_depth': model.max_depth,\n",
    "                    'min_samples_split': model.min_samples_split,\n",
    "                    'min_samples_leaf': model.min_samples_leaf,\n",
    "                    'random_state': model.random_state,\n",
    "                    'class_balancing': 'SMOTE-Tomek'\n",
    "                })\n",
    "                \n",
    "            elif model_key == 'xgboost':\n",
    "                mlflow.log_params({\n",
    "                    'model_type': 'XGBoost',\n",
    "                    'n_estimators': model.n_estimators,\n",
    "                    'max_depth': model.max_depth,\n",
    "                    'learning_rate': model.learning_rate,\n",
    "                    'subsample': model.subsample,\n",
    "                    'colsample_bytree': model.colsample_bytree,\n",
    "                    'random_state': model.random_state,\n",
    "                    'class_balancing': 'SMOTE-Tomek'\n",
    "                })\n",
    "            \n",
    "            # Log training data info (balanced)\n",
    "            mlflow.log_params({\n",
    "                'train_size_original': len(X_train),\n",
    "                'train_size_balanced': len(X_train_balanced),\n",
    "                'test_size': len(X_test),\n",
    "                'n_features': X_train.shape[1],\n",
    "                'class_0_train_original': sum(y_train == 0),\n",
    "                'class_1_train_original': sum(y_train == 1),\n",
    "                'class_0_train_balanced': sum(y_train_balanced == 0),\n",
    "                'class_1_train_balanced': sum(y_train_balanced == 1),\n",
    "                'original_imbalance_ratio': sum(y_train == 0) / sum(y_train == 1),\n",
    "                'balanced_imbalance_ratio': sum(y_train_balanced == 0) / sum(y_train_balanced == 1)\n",
    "            })\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metrics({\n",
    "                'accuracy': results['accuracy'],\n",
    "                'auc_score': results['auc_score']\n",
    "            })\n",
    "            \n",
    "            # Calculate and log additional metrics\n",
    "            y_pred = results['predictions']\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            \n",
    "            # Calculate precision, recall, f1 for each class\n",
    "            from sklearn.metrics import precision_recall_fscore_support\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "            \n",
    "            mlflow.log_metrics({\n",
    "                'precision_class_0': precision[0],\n",
    "                'recall_class_0': recall[0],\n",
    "                'f1_class_0': f1[0],\n",
    "                'precision_class_1': precision[1],\n",
    "                'recall_class_1': recall[1],\n",
    "                'f1_class_1': f1[1],\n",
    "                'true_negatives': int(tn),\n",
    "                'false_positives': int(fp),\n",
    "                'false_negatives': int(fn),\n",
    "                'true_positives': int(tp),\n",
    "                'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "                'sensitivity': tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            })\n",
    "            \n",
    "            # Log model\n",
    "            if model_key == 'xgboost':\n",
    "                mlflow.xgboost.log_model(model, \"model\", input_example=X_test.iloc[:5])\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(model, \"model\", input_example=X_test.iloc[:5])\n",
    "            \n",
    "            print(f\"âœ“ {model_name} (With SMOTE-Tomek) logged successfully\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error logging {model_name} (With SMOTE-Tomek): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1bcad-9249-4026-86d3-0ee8460f72d4",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b44a3ec-c373-47c0-9068-f329ca83065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter run ID to load model:  f9afcb24b377482e870deffbee8c33a5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'XGBoost_SMOTE'.\n",
      "2025/06/14 11:13:33 WARNING mlflow.tracking._model_registry.fluent: Run with id f9afcb24b377482e870deffbee8c33a5 has no artifacts at artifact path 'model', registering model based on models:/m-9f628abf0f184ff88a00389da52c3186 instead\n",
      "2025/06/14 11:13:33 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoost_SMOTE, version 1\n",
      "Created version '1' of model 'XGBoost_SMOTE'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'XGBoost_SMOTE'\n",
    "run_id = input(\"Enter run ID to load model: \")\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "result = mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7d0e36a-de88-4047-ada6-c4e578187aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3f47e2d1014d3eac02e687f93bdccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri = f\"models:/{model_name}@challenger\"\n",
    "\n",
    "load_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = load_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aaad83f1-9616-4a10-8627-1a918bf57b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'CreditRiskModel'.\n",
      "Copied version '1' of model 'XGBoost_SMOTE' to version '1' of model 'CreditRiskModel'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1749874485896, current_stage='None', deployment_job_state=<ModelVersionDeploymentJobState: current_task_name='', job_id='', job_state='DEPLOYMENT_JOB_CONNECTION_STATE_UNSPECIFIED', run_id='', run_state='DEPLOYMENT_JOB_RUN_STATE_UNSPECIFIED'>, description='', last_updated_timestamp=1749874485896, metrics=None, model_id=None, name='CreditRiskModel', params=None, run_id='f9afcb24b377482e870deffbee8c33a5', run_link='', source='models:/XGBoost_SMOTE/1', status='READY', status_message=None, tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dev_model_uri = f\"models:/{model_name}@challenger\"\n",
    "prod_model = \"CreditRiskModel\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=dev_model_uri,\n",
    "                          dst_name=prod_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ff66783-91f4-4992-a798-15d1b573fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069eea4d4f934dc68562350dc434b677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uri = f\"models:/{prod_model}@champion\"\n",
    "\n",
    "load_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = load_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
